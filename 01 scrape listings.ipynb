{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41464f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from time import sleep\n",
    "from slugify import slugify\n",
    "import random\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.common import exceptions\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "from selenium_stealth import stealth\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e933293c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateDriver():\n",
    "    options = webdriver.ChromeOptions() \n",
    "    options.add_argument(\"user-data-dir=selenium\")\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-dev-shm-usage') \n",
    "    options.add_argument(\"start-maximized\")\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\") \n",
    "    options.add_experimental_option('excludeSwitches', [\"enable-automation\"])\n",
    "    options.add_experimental_option('useAutomationExtension', False)\n",
    "    driver = webdriver.Chrome(options = options)\n",
    "    stealth(driver,\n",
    "            languages=[\"en-US\", \"en\"],\n",
    "            vendor=\"Google Inc.\",\n",
    "            platform=\"Win32\",\n",
    "            webgl_vendor=\"Intel Inc.\",\n",
    "            renderer=\"Intel Iris OpenGL Engine\")\n",
    "\n",
    "    driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\") \n",
    "    driver.get('https://www.liveauctioneers.com/search/')\n",
    "    return driver\n",
    "\n",
    "driver = generateDriver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95d3e865",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all done\n"
     ]
    }
   ],
   "source": [
    "slug = 'swastika'\n",
    "# urls = pd.read_csv('data/urls/urls_' + slug + '.csv')\n",
    "df = pd.read_csv('data/listings/listings_' + slug + '.csv')\n",
    "urls = pd.DataFrame(df[df['img'].isna()].url)\n",
    "i = 791\n",
    "titles = []\n",
    "dates = []\n",
    "imgs = []\n",
    "prices = []\n",
    "auctioneer_urls = []\n",
    "auctioneers = []\n",
    "breadcrumbs = []\n",
    "bidders = []\n",
    "urlz = []\n",
    "\n",
    "def scrape():\n",
    "    global i\n",
    "    global driver\n",
    "    for url in urls.url[i:]:\n",
    "        try:\n",
    "            driver.get(url)\n",
    "        except:\n",
    "            print('crashed but restarting')\n",
    "            driver = generateDriver()\n",
    "            sleep(10)\n",
    "            scrape()\n",
    "                 \n",
    "        print(url)\n",
    "        \n",
    "        try:\n",
    "            show = driver.find_element(By.CSS_SELECTOR, 'button[class*=\" FocusedItemSection__ViewItemDetailsButton-sc-\"]')\n",
    "            show.click()\n",
    "            sleep(3)\n",
    "        except exceptions.NoSuchElementException:\n",
    "            sleep(1)\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            title = WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.CSS_SELECTOR, '[data-testid=\"pageTitle\"] > div'))).get_attribute('innerHTML')\n",
    "        except TimeoutException:\n",
    "            title = ''\n",
    "        \n",
    "        try:\n",
    "            auctioneer_url = WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.CSS_SELECTOR, 'a[class*=\" AuctioneerInfo__NameLink-\"]'))).get_attribute('href')\n",
    "        except TimeoutException:\n",
    "            auctioneer_url = ''\n",
    "            \n",
    "        try:\n",
    "            auctioneer = WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.CSS_SELECTOR, '[data-testid=\"itemPageSellerName\"]'))).get_attribute('innerHTML')\n",
    "        except TimeoutException:\n",
    "            auctioneer = ''\n",
    "            \n",
    "        bcums = driver.find_elements(By.CSS_SELECTOR, '[data-testid=\"breadcrumb\"] span')\n",
    "        bcum = \" > \".join([x.get_attribute('innerHTML') for x in bcums])\n",
    "        \n",
    "        try:\n",
    "            img = WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.CSS_SELECTOR, '.item-image-primary img'))).get_attribute('src')\n",
    "            if (img.startswith('data:image')):\n",
    "                img = np.nan\n",
    "        except TimeoutException:\n",
    "            img = ''\n",
    "            \n",
    "        bidder = ''\n",
    "        date = driver.find_element(By.CSS_SELECTOR,'[class*=\"ItemPageRight__StyledItemRight\"] [data-testid=\"date-span\"] span').get_attribute('innerHTML')\n",
    "        \n",
    "        if (driver.find_elements(By.CSS_SELECTOR,'[class*=\"BidHistoryTable__TableRowDiv\"]:nth-child(2) > div:first-child')):\n",
    "            bidder = driver.find_element(By.CSS_SELECTOR,\n",
    "              '[class*=\"BidHistoryTable__TableRowDiv\"]:nth-child(2) > div:first-child').get_attribute('innerHTML')\n",
    "            \n",
    "        if (driver.find_elements(By.CSS_SELECTOR, '[class^=\"ItemBiddingStatusRow__StyledStatus\"] [class^=\"FormattedCurrency__StyledFormattedCurrency\"]')):\n",
    "            priceEl = driver.find_element(By.CSS_SELECTOR, '[class^=\"ItemBiddingStatusRow__StyledStatus\"] [class^=\"FormattedCurrency__StyledFormattedCurrency\"]')\n",
    "            price = priceEl.get_attribute('innerHTML')\n",
    "        else:\n",
    "            price = np.nan\n",
    "\n",
    "        titles.append(title)\n",
    "        dates.append(date)\n",
    "        auctioneer_urls.append(auctioneer_url)\n",
    "        auctioneers.append(auctioneer)\n",
    "        prices.append(price)\n",
    "        imgs.append(img)\n",
    "        breadcrumbs.append(bcum)\n",
    "        bidders.append(bidder)\n",
    "        urlz.append(url)\n",
    "\n",
    "        loggedIn = driver.find_element(By.CSS_SELECTOR, '[data-testid=\"loggedInMenuMe\"]')\n",
    "        actions = ActionChains(driver)\n",
    "        actions.move_to_element(loggedIn).move_by_offset(0, 40).click().perform()\n",
    "\n",
    "        i += 1\n",
    "        print(i)\n",
    "    print('all done')\n",
    "\n",
    "scrape()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "612d1bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6477"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First time\n",
    "# df = pd.DataFrame(list(zip(titles, dates, prices, breadcrumbs, bidders, auctioneers, imgs, urlz, auctioneer_urls)),\n",
    "#                   columns=['title', 'date', 'price', 'cats', 'final_bidder', 'auctioneer', 'img', 'url', 'auctioneer_url'])\n",
    "# df.to_csv('data/listings/listings_' + slug + '.csv', index = False)\n",
    "# len(df)\n",
    "\n",
    "# After\n",
    "df1 = pd.read_csv('data/listings/listings_' + slug + '.csv')\n",
    "df2 = pd.DataFrame(list(zip(titles, dates, prices, breadcrumbs, bidders, auctioneers, imgs, urlz, auctioneer_urls)),\n",
    "                  columns=['title', 'date', 'price', 'cats', 'final_bidder', 'auctioneer', 'img', 'url', 'auctioneer_url'])\n",
    "\n",
    "df3 = pd.concat([df1, df2]).drop_duplicates().reset_index(drop = True)\n",
    "df3.to_csv('data/listings/listings_' + slug + '.csv', index = False)\n",
    "len(df3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc9ed0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in nans\n",
    "df3 = pd.read_csv('data/listings/listings_swastika.csv')\n",
    "df4 = df3.loc[df3.notnull().sum(1).groupby([df3.url, df3.img]).idxmax()]\n",
    "df4[df4['img'].isna()]\n",
    "df4.to_csv('data/listings/listings_' + slug + '.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "441fac5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidate listings\n",
    "df1 = pd.read_csv('data/listings/listings_swastika.csv')\n",
    "df2 = pd.read_csv('data/listings/listings_not_swastika.csv')\n",
    "df3 = pd.concat([df1, df2], ignore_index = True).drop_duplicates('url')\n",
    "df3.to_csv('data/listings/listings_all.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
